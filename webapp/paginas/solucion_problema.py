import streamlit as st


st.markdown("""
#  Prueba Anal铆tica: Riesgo de Cr茅dito IFRS9

##  Introducci贸n

Este proyecto tiene como objetivo el desarrollo de un modelo de predicci贸n de incumplimiento de obligaciones financieras para clasificar clientes en ocho grupos de riesgo, definidos seg煤n rangos de probabilidad. El modelo se construye a partir de informaci贸n transaccional y crediticia de clientes con experiencia previa en el sistema financiero, pero bajo uso de canales bancarios.

---

##  Objetivo del Proyecto

- Predecir la probabilidad de incumplimiento (`default`) para clientes `objetivo`.
- Clasificar cada cliente en uno de los grupos [T1-T8] seg煤n su PD estimada.
- Maximizar el porcentaje de poblaci贸n **en rango** por grupo.
- Evaluar generalizaci贸n con datos fuera de muestra.

---

## Repositorio y Documentaci贸n
Para m谩s detalles sobre el proyecto, puedes consultar el repositorio en [GitHub](https://github.com/juanguzman2/prueba_ifrs9)
            
## Ingenieria de Datos

###  Principales Procesos

- **Eliminaci贸n de columnas irrelevantes:** remueve identificadores y variables que inducen fuga.
- **Derivaci贸n de variables:** crea nuevas features como `utilizacion_actual`, `relacion_saldo_cupo` o `delta_trx_mes`, 煤tiles para medir se帽ales de riesgo.
- **Transformaci贸n logar铆tmica:** normaliza distribuciones sesgadas y reduce impacto de valores extremos.
- **Discretizaci贸n de variables:** clasifica en categor铆as como `bajo`, `medio`, `alto` para facilitar reglas de negocio.
- **Winsorizaci贸n:** recorte del 10% inferior y superior en variables num茅ricas para mitigar outliers.
- **Imputaci贸n de valores nulos:** usa mediana, moda o categor铆as `desconocido`, y a帽ade banderas de imputaci贸n.
- **Eliminaci贸n de duplicados y columnas con alta nulidad.**

Todo esta almacenado en la clase Datacleaner en el archivo [data_preparation.py](https://github.com/juanguzman2/prueba_ifrs9/blob/master/src/data_preparation.py)       

## И Preprocesamiento para Modelado

La clase `ModelPreprocessor` gestiona el flujo completo de transformaci贸n de variables antes de entrenar o predecir con modelos de riesgo de cr茅dito.

###  Funcionalidades Principales

- **Limpieza opcional:** aplica el proceso de `DataCleaner` si se activa el par谩metro `apply_cleaning=True`.
- **Separaci贸n X / y:** identifica la variable objetivo (`default`) y separa las variables predictoras.
- **Transformaci贸n num茅rica:**
  - Imputaci贸n de valores nulos con mediana.
  - Escalado con `StandardScaler` para normalizar magnitudes.
- **Transformaci贸n categ贸rica:**
  - Imputaci贸n con la moda.
  - Codificaci贸n One-Hot (`OneHotEncoder`).

### 锔 Balanceo de Clases

Se encontro un gran desbalanceo de datos en la clase objetivo `Defaul`. Por lo tanto se opto por aplicar un balanceo de clases durante el entrenamiento del modelo.

Durante el entrenamiento, si `balanceo=True`, aplica una combinaci贸n:
- **Undersampling** con `RandomUnderSampler`.
- **Oversampling** con `SMOTE`.

Esto ayuda a mejorar el aprendizaje sobre la clase minoritaria (`default = 1`).

Todo esta almacenado en la clase ModelPreprocessor en el archivo [model_preprocessor.py](https://github.com/juanguzman2/prueba_ifrs9/blob/master/src/data_preprocesing.py)

##  Selecci贸n y Entrenamiento del Modelo
            

Para seleccionar el mejor modelo predictivo se aplic贸 un enfoque sistem谩tico con validaci贸n, optimizaci贸n de hiperpar谩metros y registro de resultados usando **MLflow**.

### 锔 Flujo de trabajo

1. **Carga y transformaci贸n de datos**:
   - Se aplic贸 el `ModelPreprocessor` para limpiar, transformar y balancear la data (`base_train.csv`).
   - Los datos fueron divididos en `train` y `test` con `stratify` para mantener la proporci贸n de la clase objetivo (`default`).

2. **Modelos evaluados**:
   - `Logistic Regression`
   - `Random Forest`
   - `XGBoost`
   - `LightGBM`

3. **Optimizaci贸n de hiperpar谩metros**:
   - Se utiliz贸 `GridSearchCV` con validaci贸n cruzada de 3 folds y m茅trica objetivo `F1-score`.
   - Para el modelo final (`Random Forest`), se aplic贸 una grilla extendida con combinaciones avanzadas de par谩metros como `max_depth`, `min_samples_split`, `max_features`, etc.

4. **Registro con MLflow**:
   - Cada experimento se registr贸 con nombre, par谩metros, m茅tricas (`F1`, `Precision`, `Recall`, `AUC`) y el modelo serializado para reutilizaci贸n.

###  Mejores Resultados en Validaci贸n

Modelo final entrenado: **Random Forest Optimizado**

M茅tricas en muestra de validaci贸n (`base_validacion.csv`):

- **F1-score**: `0.53`
- **Precision**: `0.47`
- **Recall**: `0.60`
- **AUC**: `0.76`

### И Validaci贸n Final

Se aplic贸 el modelo a la muestra de enero 2019 usando el preprocesador ya entrenado (`fit=False`) para simular condiciones de producci贸n. Esto garantiza consistencia y generalizaci贸n del pipeline.

Este proceso asegura la selecci贸n del mejor modelo bajo restricciones de balanceo, interpretabilidad y desempe帽o esperadas en el contexto de riesgo de cr茅dito.




            
"""
            )
import streamlit as st


st.markdown("""
# üß† Prueba Anal√≠tica: Riesgo de Cr√©dito IFRS9

## üìå Introducci√≥n

Este proyecto tiene como objetivo el desarrollo de un modelo de predicci√≥n de incumplimiento de obligaciones financieras para clasificar clientes en ocho grupos de riesgo, definidos seg√∫n rangos de probabilidad. El modelo se construy√≥ a partir de informaci√≥n transaccional y crediticia de clientes con experiencia previa en el sistema financiero, pero con bajo uso de canales bancarios.

---

## üîç Objetivo del Proyecto

- Predecir la probabilidad de incumplimiento (`default`) para clientes del tipo `objetivo`.
- Clasificar cada cliente en uno de los grupos de riesgo [T1‚ÄìT8] seg√∫n su PD estimada.
- Maximizar el porcentaje de poblaci√≥n **en rango** por grupo.
- Evaluar la capacidad de generalizaci√≥n con datos fuera de muestra.

---

## üóÇÔ∏è Repositorio del Proyecto

Para m√°s detalles t√©cnicos, c√≥digo fuente y documentaci√≥n, consulta el repositorio:

üîó [https://github.com/juanguzman2/prueba_ifrs9](https://github.com/juanguzman2/prueba_ifrs9)

---

## üß± Ingenier√≠a de Datos

### üîß Principales Procesos

- **Eliminaci√≥n de columnas irrelevantes:** excluye identificadores y variables que inducen fuga de informaci√≥n.
- **Derivaci√≥n de variables:** como `utilizacion_actual`, `relacion_saldo_cupo` y `delta_trx_mes`, √∫tiles para capturar se√±ales tempranas de riesgo.
- **Transformaci√≥n logar√≠tmica:** aplicada a variables sesgadas para estabilizar su distribuci√≥n.
- **Discretizaci√≥n:** clasificaci√≥n de variables en niveles (`bajo`, `medio`, `alto`) para facilitar reglas de negocio y segmentaci√≥n.
- **Winsorizaci√≥n:** recorte del 10% superior e inferior en variables num√©ricas para mitigar outliers extremos.
- **Imputaci√≥n de nulos:** mediante mediana, moda o categor√≠a `desconocido`, con banderas auxiliares para trazabilidad.
- **Eliminaci√≥n de duplicados y variables con alta nulidad.**

üìÑ Implementado en la clase `DataCleaner` del archivo [data_preparation.py](https://github.com/juanguzman2/prueba_ifrs9/blob/master/src/data_preparation.py)

---

## üß™ Preprocesamiento para Modelado

La clase `ModelPreprocessor` gestiona todo el flujo de transformaci√≥n previo al entrenamiento o predicci√≥n de modelos.

### Funcionalidades:

- **Limpieza opcional:** mediante `DataCleaner` (`apply_cleaning=True`).
- **Transformaci√≥n de variables:**
  - Num√©ricas: imputaci√≥n con mediana + escalado (`StandardScaler`)
  - Categ√≥ricas: imputaci√≥n con moda + codificaci√≥n (`OneHotEncoder`)
- **Manejo de columnas invisibles:** asegura consistencia entre entrenamiento y validaci√≥n.
- **Control de `inf` y columnas faltantes.**

### ‚öñÔ∏è Balanceo de Clases

Se detect√≥ un desbalance severo en la clase `default`. Para solucionarlo:

- **Undersampling** con `RandomUnderSampler`
- **Oversampling** con `SMOTE`

‚úîÔ∏è Aplicado solo en entrenamiento (`fit=True`) para evitar sesgo en validaci√≥n.

üìÑ Implementado en la clase `ModelPreprocessor` del archivo [model_preprocessor.py](https://github.com/juanguzman2/prueba_ifrs9/blob/master/src/data_preprocesing.py)

---

## ü§ñ Selecci√≥n y Entrenamiento del Modelo

Se aplic√≥ un proceso robusto de experimentaci√≥n, validaci√≥n y selecci√≥n del mejor modelo utilizando `MLflow`.

### üîÅ Flujo de trabajo

1. **Preprocesamiento:** usando `ModelPreprocessor` sobre `base_train.csv`
2. **Evaluaci√≥n de modelos base:**
   - Logistic Regression
   - Random Forest
   - XGBoost
   - LightGBM
3. **Optimizaci√≥n:**
   - `GridSearchCV` con validaci√≥n cruzada (3 folds)
   - M√©trica objetivo: `F1-score`
4. **Registro en MLflow:**
   - Almacena hiperpar√°metros, m√©tricas (`F1`, `Precision`, `Recall`, `AUC`) y artefactos serializados

### üìä Comparaci√≥n de Modelos: Preselecci√≥n vs Optimizaci√≥n

| Modelo                 | F1 Score | Precisi√≥n | Recall |
|------------------------|----------|-----------|--------|
| LogisticRegression_HPO | 0.54     | 0.42      | 0.74   |
| RandomForest_HPO       | 0.54     | 0.47      | 0.62   |
| XGBoost_HPO            | **0.55** | **0.44**  | **0.75** |
| LightGBM_HPO           | 0.54     | 0.43      | 0.70   |
| **XGBoost_Optimized**  | 0.54     | 0.43      | 0.75   |

‚úÖ **XGBoost Optimizado** fue seleccionado como modelo final por su desempe√±o balanceado y estabilidad con datos fuera de muestra (201901).

El modelo fue almacenado en un archivo `.pkl` para su uso posterior. La ubicacion del modelo es: [Model.pkl](https://github.com/juanguzman2/prueba_ifrs9/blob/master/models/model.pkl)

üìà Visualizaci√≥n de MLflow:
![MLflow Results](https://github.com/juanguzman2/prueba_ifrs9/blob/master/images/MLFlow.png?raw=true)

---

## üîÆ API de Predicci√≥n de Riesgo de Cr√©dito

Una vez entrenado el modelo final, se implement√≥ una API REST para consumo externo.

### üì• Endpoint: `/predict/`

- **M√©todo:** `POST`
- **Tipo de contenido:** `multipart/form-data`
- **Par√°metro:** `file` ‚Äî archivo `.csv` separado por `|` con la misma estructura de variables del entrenamiento.

üìÑ L√≥gica implementada en el archivo [app.py](https://github.com/juanguzman2/prueba_ifrs9/blob/master/api/app.py)

---

### üß† L√≥gica Interna de Predicci√≥n

La API utiliza la clase `RiskPredictor` para realizar todo el flujo de predicci√≥n, que incluye:

1. **Carga del modelo serializado** desde disco (`model.pkl`) usando `joblib`.
2. **Transformaci√≥n de los datos** de entrada con una instancia del `ModelPreprocessor` (sin rebalanceo en producci√≥n).
3. **Predicci√≥n de probabilidad de incumplimiento** (`y_proba = model.predict_proba(X)[:, 1]`).
4. **Asignaci√≥n de grupo de riesgo** (`t1` a `t8`) usando reglas basadas en rangos de PD definidos por negocio.
5. **Validaci√≥n de que todas las predicciones caen en un grupo permitido**.

üìÑ C√≥digo fuente: [`predict.py`](https://github.com/juanguzman2/prueba_ifrs9/blob/master/src/predict.py)

---

### üì§ Respuesta esperada (formato JSON)

```json
[
  {
    "num_doc": "12345678",
    "probabilidad": 0.0324,
    "grupo_riesgo": "t4"
  },
  ...
]
```

---

## üìå Recomendaciones y Datos Adicionales

Para mejorar a√∫n m√°s la efectividad del modelo, ser√≠a ideal incorporar:

- **Datos de scoring externos** (Bur√≥ de cr√©dito)
- **Variables socioecon√≥micas** del cliente (ciudad, ingresos)
- **Datos temporales o secuenciales** (historial mensual de mora)
- **Alertas tempranas** en canales alternos (APPs, call center)
- **Variables macroecon√≥micas** (tasas de inter√©s, inflaci√≥n)

üìâ Estos datos podr√≠an obtenerse con bajo costo si ya forman parte del core transaccional o CRM de la entidad.

            
## üß© Estrategia Te√≥rica para Disponibilizar el Modelo

Para facilitar el consumo del modelo por servicios externos o usuarios finales, se plantea la siguiente soluci√≥n te√≥rica:

- El modelo entrenado se **serializa en formato `.pkl`** para garantizar su reutilizaci√≥n y trazabilidad.
- Se expone una **API REST construida con FastAPI**, que permite recibir archivos de entrada (`.csv`) y retornar las predicciones de riesgo (`grupo_riesgo`).
- Para mejorar la interacci√≥n, se puede desarrollar una **interfaz web en FastAPI o Streamlit** que permita a usuarios cargar archivos, visualizar resultados y descargar reportes de clasificaci√≥n.

Este enfoque asegura que los resultados del modelo sean f√°cilmente accesibles por sistemas web, m√≥viles o procesos de negocio automatizados sin necesidad de redearrollar el modelo.

"""
            
           
            )